Model,Model_Size_B,Mean_Score,Std_Score,Median_Score,Min_Score,Max_Score
Mistral-7B-v0.1,7,0.44086956521739135,0.35657710242789015,0.55,0.0,1.0
deepseek-llm-7b-chat,7,0.45190760869565216,0.4978780885109387,0.0,0.0,1.5
Qwen2.5-7B-Instruct,7,0.8276630434782607,0.1526461394838521,0.85,0.0,1.0
Meta-Llama-3-8B,8,0.5275543478260869,0.3335827821695347,0.6,0.0,1.0
aya-expanse-8b,8,0.7177934782608695,0.2615755825308534,0.85,0.0,1.0
